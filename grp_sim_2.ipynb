{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d333eb-86f8-40fd-af1c-983805d3079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Parallel Simulation (K=3, D=4)\n",
      "Total Nodes = 12\n",
      "Communication Mode = INT8\n",
      "\n",
      "Simulation Completed.\n",
      "\n",
      "Replica Consistency Check:\n",
      "  Stage 0: Max Weight Difference = 0.00024210211995523423\n",
      "  Stage 1: Max Weight Difference = 0.0003216343466192484\n",
      "  Stage 2: Max Weight Difference = 0.0002757864131126553\n",
      "\n",
      "Communication Statistics:\n",
      "  Total Communication Bytes = 2160\n",
      "\n",
      "================ EXECUTION TIMELINE ================\n",
      "\n",
      "Time   | Rank   | Stage  | Event\n",
      "--------------------------------\n",
      "0      | 0      | 0      | F0\n",
      "1      | 2      | 2      | B0\n",
      "2      | 3      | 0      | F0\n",
      "3      | 5      | 2      | B0\n",
      "4      | 6      | 0      | F0\n",
      "5      | 8      | 2      | B0\n",
      "6      | 9      | 0      | F0\n",
      "7      | 11     | 2      | B0\n",
      "8      | 0      | 0      | F1\n",
      "9      | 1      | 1      | F0\n",
      "10     | 1      | 1      | B0\n",
      "11     | 2      | 2      | B1\n",
      "12     | 3      | 0      | F1\n",
      "13     | 4      | 1      | F0\n",
      "14     | 4      | 1      | B0\n",
      "15     | 5      | 2      | B1\n",
      "16     | 6      | 0      | F1\n",
      "17     | 7      | 1      | F0\n",
      "18     | 7      | 1      | B0\n",
      "19     | 8      | 2      | B1\n",
      "20     | 9      | 0      | F1\n",
      "21     | 10     | 1      | F0\n",
      "22     | 10     | 1      | B0\n",
      "23     | 11     | 2      | B1\n",
      "24     | 0      | 0      | F2\n",
      "25     | 0      | 0      | B0\n",
      "26     | 1      | 1      | F1\n",
      "27     | 1      | 1      | B1\n",
      "28     | 2      | 2      | F0\n",
      "29     | 2      | 2      | B2\n",
      "30     | 3      | 0      | F2\n",
      "31     | 3      | 0      | B0\n",
      "32     | 4      | 1      | F1\n",
      "33     | 4      | 1      | B1\n",
      "34     | 5      | 2      | F0\n",
      "35     | 5      | 2      | B2\n",
      "36     | 6      | 0      | F2\n",
      "37     | 6      | 0      | B0\n",
      "38     | 7      | 1      | F1\n",
      "39     | 7      | 1      | B1\n",
      "40     | 8      | 2      | F0\n",
      "41     | 8      | 2      | B2\n",
      "42     | 9      | 0      | F2\n",
      "43     | 9      | 0      | B0\n",
      "44     | 10     | 1      | F1\n",
      "45     | 10     | 1      | B1\n",
      "46     | 11     | 2      | F0\n",
      "47     | 11     | 2      | B2\n",
      "48     | 0      | 0      | F3\n",
      "49     | 0      | 0      | B1\n",
      "50     | 1      | 1      | F2\n",
      "51     | 1      | 1      | B2\n",
      "52     | 2      | 2      | F1\n",
      "53     | 2      | 2      | B3\n",
      "54     | 3      | 0      | F3\n",
      "55     | 3      | 0      | B1\n",
      "56     | 4      | 1      | F2\n",
      "57     | 4      | 1      | B2\n",
      "58     | 5      | 2      | F1\n",
      "59     | 5      | 2      | B3\n",
      "60     | 6      | 0      | F3\n",
      "61     | 6      | 0      | B1\n",
      "62     | 7      | 1      | F2\n",
      "63     | 7      | 1      | B2\n",
      "64     | 8      | 2      | F1\n",
      "65     | 8      | 2      | B3\n",
      "66     | 9      | 0      | F3\n",
      "67     | 9      | 0      | B1\n",
      "68     | 10     | 1      | F2\n",
      "69     | 10     | 1      | B2\n",
      "70     | 11     | 2      | F1\n",
      "71     | 11     | 2      | B3\n",
      "72     | 0      | 0      | F4\n",
      "73     | 0      | 0      | B2\n",
      "74     | 1      | 1      | F3\n",
      "75     | 1      | 1      | B3\n",
      "76     | 2      | 2      | F2\n",
      "77     | 2      | 2      | B4\n",
      "78     | 3      | 0      | F4\n",
      "79     | 3      | 0      | B2\n",
      "80     | 4      | 1      | F3\n",
      "81     | 4      | 1      | B3\n",
      "82     | 5      | 2      | F2\n",
      "83     | 5      | 2      | B4\n",
      "84     | 6      | 0      | F4\n",
      "85     | 6      | 0      | B2\n",
      "86     | 7      | 1      | F3\n",
      "87     | 7      | 1      | B3\n",
      "88     | 8      | 2      | F2\n",
      "89     | 8      | 2      | B4\n",
      "90     | 9      | 0      | F4\n",
      "91     | 9      | 0      | B2\n",
      "92     | 10     | 1      | F3\n",
      "93     | 10     | 1      | B3\n",
      "94     | 11     | 2      | F2\n",
      "95     | 11     | 2      | B4\n",
      "96     | 0      | 0      | F5\n",
      "97     | 0      | 0      | B3\n",
      "98     | 1      | 1      | F4\n",
      "99     | 1      | 1      | B4\n",
      "100    | 2      | 2      | F3\n",
      "101    | 2      | 2      | B5\n",
      "102    | 3      | 0      | F5\n",
      "103    | 3      | 0      | B3\n",
      "104    | 4      | 1      | F4\n",
      "105    | 4      | 1      | B4\n",
      "106    | 5      | 2      | F3\n",
      "107    | 5      | 2      | B5\n",
      "108    | 6      | 0      | F5\n",
      "109    | 6      | 0      | B3\n",
      "110    | 7      | 1      | F4\n",
      "111    | 7      | 1      | B4\n",
      "112    | 8      | 2      | F3\n",
      "113    | 8      | 2      | B5\n",
      "114    | 9      | 0      | F5\n",
      "115    | 9      | 0      | B3\n",
      "116    | 10     | 1      | F4\n",
      "117    | 10     | 1      | B4\n",
      "118    | 11     | 2      | F3\n",
      "119    | 11     | 2      | B5\n",
      "120    | 0      | 0      | B4\n",
      "121    | 1      | 1      | B5\n",
      "122    | 3      | 0      | B4\n",
      "123    | 4      | 1      | B5\n",
      "124    | 6      | 0      | B4\n",
      "125    | 7      | 1      | B5\n",
      "126    | 9      | 0      | B4\n",
      "127    | 10     | 1      | B5\n",
      "128    | 0      | 0      | B5\n",
      "129    | 3      | 0      | B5\n",
      "130    | 6      | 0      | B5\n",
      "131    | 9      | 0      | B5\n",
      "132    | 0      | 0      | OPT\n",
      "133    | 3      | 0      | OPT\n",
      "134    | 6      | 0      | OPT\n",
      "135    | 9      | 0      | OPT\n",
      "136    | 1      | 1      | OPT\n",
      "137    | 4      | 1      | OPT\n",
      "138    | 7      | 1      | OPT\n",
      "139    | 10     | 1      | OPT\n",
      "140    | 2      | 2      | OPT\n",
      "141    | 5      | 2      | OPT\n",
      "142    | 8      | 2      | OPT\n",
      "143    | 11     | 2      | OPT\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Configuration (Modify for Experiments)\n",
    "# ============================================================\n",
    "\n",
    "K = 3                 # Pipeline stages\n",
    "D = 4                 # Data parallel replicas\n",
    "M = 6                 # Micro-batches\n",
    "GRAD_SIZE = 120       # Must be divisible by D\n",
    "COMM_MODE = \"INT8\"    # \"FP16\" or \"INT8\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Quantization Utilities\n",
    "# ============================================================\n",
    "\n",
    "def quantize_int8(t):\n",
    "    max_val = np.max(np.abs(t))\n",
    "    scale = max_val / 127.0 if max_val != 0 else 1.0\n",
    "    q = np.round(t / scale).astype(np.int8)\n",
    "    return q, scale\n",
    "\n",
    "def dequantize_int8(q, scale):\n",
    "    return q.astype(np.float32) * scale\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Device Definition\n",
    "# ============================================================\n",
    "\n",
    "class Device:\n",
    "    def __init__(self, rank, stage):\n",
    "        self.rank = rank\n",
    "        self.stage = stage\n",
    "        self.weight = np.ones(GRAD_SIZE, dtype=np.float32)\n",
    "        self.local_grad = np.zeros(GRAD_SIZE, dtype=np.float32)\n",
    "        self.comm_bytes = 0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hybrid Parallel Simulator\n",
    "# ============================================================\n",
    "\n",
    "class HybridSimulator:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.devices = []\n",
    "        self.timeline = []\n",
    "        self.logical_time = 0\n",
    "\n",
    "        # Create K × D devices\n",
    "        for dp in range(D):\n",
    "            for stage in range(K):\n",
    "                rank = dp * K + stage\n",
    "                self.devices.append(Device(rank, stage))\n",
    "\n",
    "        # Group by pipeline stage (Data Parallel groups)\n",
    "        self.stage_groups = {\n",
    "            s: [d for d in self.devices if d.stage == s]\n",
    "            for s in range(K)\n",
    "        }\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def log(self, rank, event):\n",
    "        self.timeline.append((self.logical_time, rank, event))\n",
    "        self.logical_time += 1\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1F1B Pipeline Scheduling\n",
    "    # --------------------------------------------------------\n",
    "    def run_pipeline(self):\n",
    "\n",
    "        total_steps = M + K - 1\n",
    "\n",
    "        for step in range(total_steps):\n",
    "\n",
    "            for d in self.devices:\n",
    "\n",
    "                stage = d.stage\n",
    "                warmup = K - stage - 1\n",
    "\n",
    "                # Forward Phase\n",
    "                if step < M and step >= stage:\n",
    "                    self.log(d.rank, f\"F{step - stage}\")\n",
    "\n",
    "                # Backward Phase\n",
    "                if step >= warmup:\n",
    "                    mb = step - warmup\n",
    "                    if 0 <= mb < M:\n",
    "                        self.log(d.rank, f\"B{mb}\")\n",
    "\n",
    "                        # Gradient accumulation\n",
    "                        grad = np.random.randn(GRAD_SIZE).astype(np.float32)\n",
    "                        d.local_grad += grad\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # True Chunked Ring All-Reduce (Deterministic)\n",
    "    # --------------------------------------------------------\n",
    "    def ring_all_reduce(self, stage):\n",
    "\n",
    "        group = self.stage_groups[stage]\n",
    "\n",
    "        # Stack gradients (D × GRAD_SIZE)\n",
    "        grads = np.stack([d.local_grad for d in group])\n",
    "        chunks = np.split(grads, D, axis=1)\n",
    "\n",
    "        # -------- Reduce-Scatter --------\n",
    "        for step in range(D - 1):\n",
    "            for i in range(D):\n",
    "                src = i\n",
    "                dst = (i + 1) % D\n",
    "                chunk_idx = (i - step) % D\n",
    "\n",
    "                send_chunk = chunks[chunk_idx][src]\n",
    "\n",
    "                if COMM_MODE == \"FP16\":\n",
    "                    payload = send_chunk.astype(np.float16)\n",
    "                    group[src].comm_bytes += payload.nbytes\n",
    "                    recv_chunk = payload.astype(np.float32)\n",
    "                else:\n",
    "                    q, scale = quantize_int8(send_chunk)\n",
    "                    group[src].comm_bytes += q.nbytes\n",
    "                    recv_chunk = dequantize_int8(q, scale)\n",
    "\n",
    "                target_idx = (dst - step - 1) % D\n",
    "                chunks[target_idx][dst] += recv_chunk\n",
    "\n",
    "        # -------- All-Gather --------\n",
    "        for step in range(D - 1):\n",
    "            for i in range(D):\n",
    "                src = i\n",
    "                dst = (i + 1) % D\n",
    "                chunk_idx = (i - step) % D\n",
    "\n",
    "                send_chunk = chunks[chunk_idx][src]\n",
    "\n",
    "                if COMM_MODE == \"FP16\":\n",
    "                    payload = send_chunk.astype(np.float16)\n",
    "                    group[src].comm_bytes += payload.nbytes\n",
    "                    recv_chunk = payload.astype(np.float32)\n",
    "                else:\n",
    "                    q, scale = quantize_int8(send_chunk)\n",
    "                    group[src].comm_bytes += q.nbytes\n",
    "                    recv_chunk = dequantize_int8(q, scale)\n",
    "\n",
    "                target_idx = (dst - step - 1) % D\n",
    "                chunks[target_idx][dst] = recv_chunk\n",
    "\n",
    "        # Average\n",
    "        final = np.concatenate(chunks, axis=1) / D\n",
    "\n",
    "        for i, d in enumerate(group):\n",
    "            d.local_grad = final[i]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def optimizer_step(self, stage):\n",
    "\n",
    "        for d in self.stage_groups[stage]:\n",
    "            self.log(d.rank, \"OPT\")\n",
    "            d.weight -= 0.01 * d.local_grad\n",
    "            d.local_grad[:] = 0\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def run(self):\n",
    "\n",
    "        print(f\"\\nHybrid Parallel Simulation (K={K}, D={D})\")\n",
    "        print(f\"Total Nodes = {K * D}\")\n",
    "        print(f\"Communication Mode = {COMM_MODE}\\n\")\n",
    "\n",
    "        # 1F1B Pipeline\n",
    "        self.run_pipeline()\n",
    "\n",
    "        # Data Parallel Synchronization\n",
    "        for stage in range(K):\n",
    "            self.ring_all_reduce(stage)\n",
    "            self.optimizer_step(stage)\n",
    "\n",
    "        print(\"Simulation Completed.\\n\")\n",
    "\n",
    "        self.verify()\n",
    "        self.report_comm()\n",
    "        self.print_timeline()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def verify(self):\n",
    "\n",
    "        print(\"Replica Consistency Check:\")\n",
    "        for stage in range(K):\n",
    "            weights = [d.weight for d in self.stage_groups[stage]]\n",
    "            diffs = [np.linalg.norm(weights[0] - w) for w in weights]\n",
    "            print(f\"  Stage {stage}: Max Weight Difference = {max(diffs)}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def report_comm(self):\n",
    "\n",
    "        total = sum(d.comm_bytes for d in self.devices)\n",
    "        print(\"\\nCommunication Statistics:\")\n",
    "        print(f\"  Total Communication Bytes = {total}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def print_timeline(self):\n",
    "\n",
    "        print(\"\\n================ EXECUTION TIMELINE ================\\n\")\n",
    "\n",
    "        header = f\"{'Time':<6} | {'Rank':<6} | {'Stage':<6} | Event\"\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))\n",
    "\n",
    "        for t, rank, event in self.timeline:\n",
    "            stage = self.devices[rank].stage\n",
    "            print(f\"{t:<6} | {rank:<6} | {stage:<6} | {event}\")\n",
    "\n",
    "        print(\"\\n====================================================\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    HybridSimulator().run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985e89f-152c-4bfd-998a-5208d3366bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
